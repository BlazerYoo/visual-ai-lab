<div class="flex flex-col">

  
  <div class="flex flex-wrap mt-16 md:mt-20 lg:mt-36 mb-10 mx-10 sm:mx-16 lg:mx-16 xl:mx-20 2xl:mx-32 sm:mb-20">
    
    <div class="flex lg:w-5/12 pr-3 sm:pr-4 md:pr-8 lg:pr-12 rounded-lg mb-6"><img src="assets/lab_photo.png" class="object-contain rounded-lg"></div>
    
    <div class="flex lg:w-7/12 mb-6">
      <div
        class="border-l-8 pl-3 sm:pl-4 md:pl-8 lg:pl-12 border-orange-400 border-dashed text-start font-bold leading-loose">
        <span class="text-base sm:text-lg md:text-xl lg:text-2xl xl:text-3xl 2xl:text-4xl">We work on developing artificially intelligent systems
          that are able to reason about the visual world. Our research brings together the fields of
  
          <span class="text-orange-grad">computer vision,</span>
          <span class="text-orangerev-grad">machine learning,</span>
          <span class="text-green-grad">human-computer interaction,</span>
          <span class="text-greenrev-grad">cognitive science,</span> as well as
          <span class="text-blue-grad">fairness,</span>
          <span class="text-bluerev-grad">accountability,</span> and
          <span class="text-outline">transparency</span>.
        </span>
      </div>
    </div>
  </div>

  
  <div class="text-center text-sm sm:text-xl 2xl:text-2xl font-thin leading-loose mx-10 sm:mx-16 md:mx-16 lg:mx-20 xl:mx-32">
    We are interested in a diverse range of topics, including building computer vision systems, understanding the
    underlying learning paradigms, studying how computer vision systems can effectively collaborate with humans,
    and ensuring the fairness of the vision systems with respect to people of all backgrounds by
    improving dataset design, algorithmic methodology, measurement metrics and model interpretability.
  </div>

</div> 

<div class="flex w-full justify-center mb-10 sm:mb-20">
</div>

<div class="flex flex-wrap xl:mx-16 justify-around">
  <div class="w-10/12 xl:w-6/12 lg:mx-10">
    <div class="relative flex py-5 items-center">
      <div class="flex-grow border-t border-2 border-orange-400 mr-2"></div>
      <span class="text-orange-400 font-bold font-mono text-2xl text-center">RECENT TIMELINE</span>
      <div class="flex-grow border-t border-2 border-orange-400 ml-2"></div>
    </div>
    <div class="mt-16">
      <ul class="timeline timeline-snap-icon max-md:timeline-compact timeline-vertical">
                                              
                      <li>
              <div class="timeline-middle">
                <span class="relative flex h-4 w-4">
                  <span
                    class="animate-ping absolute inline-flex h-full w-full rounded-full bg-orange-400 opacity-75"></span>
                  <span class="relative inline-flex rounded-full h-4 w-4 bg-orange-500"></span>
                </span>
              </div>
              <div class="timeline-start md:text-end">
                <time class="font-mono italic">
                  November 2024                </time>

                <div class="grid grid-rows-2 justify-items-center grid-flow-col sm:gap-1 text-center">
                  
                  
                  <div class="row-span-2 text-xs text-start text-wrap md:text-end sm:text-sm lg:text-base">
                    <div class="font-black">
                                              <a href="https://www.cell.com/patterns/fulltext/S2666-3899%2824%2900239-3" class="hover:underline">&#34;Benchmark Suites Instead of Leaderboards for Evaluating AI Fairness&#34; accepted to Patterns 2024 </a>
                                            </div>
                    <div>Angelina Wang, Aaron Hertzmann, Olga Russakovsky, et al.</div>
                  </div>

                                  </div>
              </div>
              <hr />
            </li>
                                                                      
                      <li>
              <hr />
              <div class="timeline-middle">
                <span class="relative flex h-4 w-4">
                  <span
                    class="animate-ping absolute inline-flex h-full w-full rounded-full bg-orange-400 opacity-75"></span>
                  <span class="relative inline-flex rounded-full h-4 w-4 bg-orange-500"></span>
                </span>
              </div>
              <div class="timeline-end">
                <time class="font-mono italic">
                  September 2024                </time>

                <div class="grid grid-rows-2 justify-items-center grid-flow-col sm:gap-1 text-center">
                  <div class="row-span-2 text-xs sm:text-sm lg:text-base text-start">
                    <div class="font-black">
                                              <a href="https://www.siebelscholars.com/scholar-profile/3840/" class="hover:underline">Siebel Scholars</a>
                                            </div>
                    <div>Sunnie S. Y. Kim</div>
                  </div>
                                      <div class="avatar h-10 w-10 sm:h-16 sm:w-16 lg:h-20 lg:w-20"> 
                      <div class="rounded-full">
                        <img src="assets/sunnie_s_y_kim.jpg">
                      </div>
                    </div>
                                  </div>
              </div>
              <hr />
            </li>
                                                
                      <li>
              <div class="timeline-middle">
                <span class="relative flex h-4 w-4">
                  <span
                    class="animate-ping absolute inline-flex h-full w-full rounded-full bg-orange-400 opacity-75"></span>
                  <span class="relative inline-flex rounded-full h-4 w-4 bg-orange-500"></span>
                </span>
              </div>
              <div class="timeline-start md:text-end">
                <time class="font-mono italic">
                  August 2024                </time>

                <div class="grid grid-rows-2 justify-items-center grid-flow-col sm:gap-1 text-center">
                  
                  
                  <div class="row-span-2 text-xs text-start text-wrap md:text-end sm:text-sm lg:text-base">
                    <div class="font-black">
                                              <a href="https://arxiv.org/abs/2308.07545" class="hover:underline">&#34;Vision-Language Dataset Distillation&#34; accepted to TMLR 2024 </a>
                                            </div>
                    <div>Xindi Wu, Byron Zhang, Zhiwei Deng, et al.</div>
                  </div>

                                  </div>
              </div>
              <hr />
            </li>
                                                
                      <li>
              <hr />
              <div class="timeline-middle">
                <span class="relative flex h-4 w-4">
                  <span
                    class="animate-ping absolute inline-flex h-full w-full rounded-full bg-orange-400 opacity-75"></span>
                  <span class="relative inline-flex rounded-full h-4 w-4 bg-orange-500"></span>
                </span>
              </div>
              <div class="timeline-end">
                <time class="font-mono italic">
                  July 2024                </time>

                <div class="grid grid-rows-2 justify-items-center grid-flow-col sm:gap-1 text-center">
                  <div class="row-span-2 text-xs sm:text-sm lg:text-base text-start">
                    <div class="font-black">
                                              <a href="https://arxiv.org/abs/2403.19669" class="hover:underline">&#34;Analyzing the Roles of Language and Vision in Learning from Limited Data&#34; accepted to CogSci 2024 </a>
                                            </div>
                    <div>Allison Chen, Ilia Sucholutsky, Olga Russakovsky, et al.</div>
                  </div>
                                  </div>
              </div>
              <hr />
            </li>
                                                
                      <li>
              <div class="timeline-middle">
                <span class="relative flex h-4 w-4">
                  <span
                    class="animate-ping absolute inline-flex h-full w-full rounded-full bg-orange-400 opacity-75"></span>
                  <span class="relative inline-flex rounded-full h-4 w-4 bg-orange-500"></span>
                </span>
              </div>
              <div class="timeline-start md:text-end">
                <time class="font-mono italic">
                  May 2024                </time>

                <div class="grid grid-rows-2 justify-items-center grid-flow-col sm:gap-1 text-center">
                  
                  
                  <div class="row-span-2 text-xs text-start text-wrap md:text-end sm:text-sm lg:text-base">
                    <div class="font-black">
                                              <a href="https://arxiv.org/abs/2310.01755" class="hover:underline">&#34;ImageNet-OOD: Deciphering Modern Out-of-Distribution Detection Algorithms&#34; accepted to ICLR 2024 </a>
                                            </div>
                    <div>William Yang, Byron Zhang, Olga Russakovsky, et al.</div>
                  </div>

                                  </div>
              </div>
              <hr />
            </li>
                                                
                      <li>
              <hr />
              <div class="timeline-middle">
                <span class="relative flex h-4 w-4">
                  <span
                    class="animate-ping absolute inline-flex h-full w-full rounded-full bg-orange-400 opacity-75"></span>
                  <span class="relative inline-flex rounded-full h-4 w-4 bg-orange-500"></span>
                </span>
              </div>
              <div class="timeline-end">
                <time class="font-mono italic">
                  May 2024                </time>

                <div class="grid grid-rows-2 justify-items-center grid-flow-col sm:gap-1 text-center">
                  <div class="row-span-2 text-xs sm:text-sm lg:text-base text-start">
                    <div class="font-black">
                                              <a href="https://arxiv.org/abs/2406.04284" class="hover:underline">&#34;What is Dataset Distillation Learning?&#34; accepted to ICML 2024 </a>
                                            </div>
                    <div>William Yang, Ye Zhu, Zhiwei Deng, et al.</div>
                  </div>
                                  </div>
              </div>
              <hr />
            </li>
                                                                      
                      <li>
              <div class="timeline-middle">
                <span class="relative flex h-4 w-4">
                  <span
                    class="animate-ping absolute inline-flex h-full w-full rounded-full bg-orange-400 opacity-75"></span>
                  <span class="relative inline-flex rounded-full h-4 w-4 bg-orange-500"></span>
                </span>
              </div>
              <div class="timeline-start md:text-end">
                <time class="font-mono italic">
                  April 2024                </time>

                <div class="grid grid-rows-2 justify-items-center grid-flow-col sm:gap-1 text-center">
                  
                                      <div class="avatar h-0 w-0 md:h-16 md:w-16 lg:h-20 lg:w-20 invisible md:visible"> 
                      <div class="rounded-full">
                        <img src="assets/allison_chen.jpg">
                      </div>
                    </div>
                  
                  <div class="row-span-2 text-xs text-start text-wrap md:text-end sm:text-sm lg:text-base">
                    <div class="font-black">
                                              <a href="https://www.nsfgrfp.org/" class="hover:underline">NSF Graduate Fellowship Award</a>
                                            </div>
                    <div>Allison Chen</div>
                  </div>

                                      <div class="avatar h-10 w-10 sm:h-16 sm:w-16 md:h-0 md:w-0 visible md:invisible"> 
                      <div class="rounded-full">
                        <img src="assets/allison_chen.jpg">
                      </div>
                    </div>
                                  </div>
              </div>
              <hr />
            </li>
                        </ul>
    </div>
  </div>

  <div class="flex flex-col mt-10 sm:mt-20 mx-10 w-10/12 xl:w-4/12">
    <div class="text-orange-400 font-bold font-mono text-2xl mt-5">ACKNOWLEDGEMENTS</div>

    <div class="leading-loose">
      We are very grateful to the National Science Foundation, Open Philanthropy, Cisco, Amazon, Adobe, Princeton School of Engineering and Applied Sciences, Princeton Alliance for Collaborative Research and Innovation, and Princeton Precision Health Initiative (current/ongoing) as well as to KAUST, Samsung, Google, Meta, Microsoft, and Princeton Center for Statistics and Machine Learning (past) for generous support of our research.    </div>
    
  </div>
</div>

<div class="h-40"></div>