<!DOCTYPE html>
<html lang='en'>

<head>
    <base href=".">
    <link rel="shortcut icon" type="image/png" href="assets/favicon.png"/>
    <link rel="stylesheet" type="text/css" media="all" href="assets/main.css"/>
    <meta name="description" content="Future of Computer Vision Datasets">
    <meta name="resource-type" content="document">
    <meta name="distribution" content="global">
    <meta name="KeyWords" content="Conference">
    <title>Future of Computer Vision Datasets</title>
</head>

<body>
<div class="banner" style="padding:15px; text-align:center;">
<div class="banner-content">
<h1>Future of Computer Vision Datasets</h1>
<h3> <a href="http://cvpr2021.thecvf.com/">CVPR 2021 Workshop </a> </h3>
<h3 style="margin-bottom:3cm; text-align:center;"> June 20, 2021 </h3>    
    
    
    
    
   <!-- <h3 style="color:#b8860b">
     We're looking for diverse viewpoints to contribute to the discussion! Please fill out <a href="https://forms.gle/F5gX4L7jmnxZJCSQ9" style="color:#b2132e">this form.</a></h3>
    -->
    <h3 style="text-align:center"> <a href="voices.html">Voices of our community</a>
     </h3>
    <h3 style="text-align:center"> <a href="workshop.html">Videos from the workshop</a>
     </h3>
    
    <h3>Overview</h3>
    <p>
    The workshop will focus on an in-depth discussion of the future of ethical, responsible, privacy-aware dataset construction, focussed around a single key question:
    </p >
    <p style="text-align:center;">"What are the necessary and sufficient guidelines, tools, and frameworks for building responsible and socially-aware future computer vision datasets?"
    </p>
    
    <p>The following topics are within scope for the workshop: </p>
    <ul>
    <li> Recent advances in large-scale dataset collection with an eye towards social awareness </li>
    <li> Goals, requirements and best practices for future dataset collection and collectors </li>
    <li> Methods for ensuring diversity and representation in large-scale datasets </li>
    <li> Privacy-aware and privacy-preserving methods in image collection and annotation </li>
    <li> Ethical dilemmas in dataset collection </li>
    <li> Different sources of visual data, along with the pros, cons and challenges of each </li>
    <li> Necessary, sufficient, and/or appropriate safeguards to enforce in the computer vision community around dataset construction </li>
    </ul>
    

    <!--<p> We're looking for diverse viewpoints to contribute to the discussion! Please fill out <a href="https://forms.gle/F5gX4L7jmnxZJCSQ9">this form.</a></p>
    -->
    
    <h3>Invited Speakers</h3>
        <table><tbody>

          <tr>
           <td style="padding:20px;width:30%;vertical-align:middle;text-align:center">
              <img src='images/edenton150x150.png' style="width:100%">
            </td> 

            <td style="padding:20px;width:70%;vertical-align:middle">
            <a href="https://cephaloponderer.com">Dr. Emily Denton</a> <br>
            Dr. Emily Denton is a Research Scientist on Googleâ€™s Ethical AI team, studying the societal impacts of machine learning and AI technology. Their recent research centers on critically examining the norms, values, and work practices that structure the development and use of machine learning datasets. Prior to joining Google, Dr. Denton received their PhD in machine learning from the Courant Institute of Mathematical Sciences at New York University, focusing on unsupervised learning and generative modeling of images and video. They also volunteer with <a href="https://outintech.com/">Out in Tech</a>, where they help coordinate an LGBTQ+ youth mentorship program.
            </td>
          </tr>
          <tr>
           <td style="padding:20px;width:30%;vertical-align:middle;text-align:center">
              <img src='images/malik-color-small.gif' style="width:100%">
            </td> 

            <td style="padding:20px;width:70%;vertical-align:middle">
            <a href="http://people.eecs.berkeley.edu/~malik/">Dr. Jitendra Malik </a> <br>
            Prof. Jitendra Malik is currently the Arthur J. Chick Professor in the Department of Electrical Engineering and Computer Science at Berkeley, as well as the Research Director and Site Lead of Facebook AI Research in Menlo Park. Prof. Malik's research group has worked on many different topics in computer vision, computational modeling of human vision, computer graphics and the analysis of biological images. He is the recipient of numerous awards, including the 2016 ACM-AAAI Allen Newell Award, the 2018 IJCAI Award for Research Excellence in AI, and the 2019 IEEE Computer Society Computer Pioneer Award.
            
            </td>
          </tr>
          
<!--          <tr>
           <td style="padding:20px;width:30%;vertical-align:middle;text-align:center">
              <img src='images/caroline_pantofaru.jpg' style="width:100%">
            </td> 

            <td style="padding:20px;width:70%;vertical-align:middle">
            <a href=" https://research.google/people/CarolinePantofaru/">Dr. Caroline Pantofaru</a> <br>
           Dr. Caroline Pantofaru is a senior researcher at Google. She is an expert in computer vision and robotics, and leads a team at Google focusing on engineering innovations that reduce bias in large-scale visual recognition systems. Recently she worked to construct the large-scale action recognition dataset <a href="https://openaccess.thecvf.com/content_cvpr_2018/html/Gu_AVA_A_Video_CVPR_2018_paper.html">AVA </a> and the led the follow-up <a href="https://arxiv.org/abs/1901.01342">AVA-ActiveSpeaker dataset </a> effort. She obtained her PhD from Carnegie Mellon. 
            </td>
          </tr>
-->    
          <tr>
           <td style="padding:20px;width:30%;vertical-align:middle;text-align:center">
              <img src='images/Raquel-profile.jpg' style="width:100%">
            </td> 

            <td style="padding:20px;width:70%;vertical-align:middle">
            <a href="http://www.cs.toronto.edu/~urtasun/"> Dr. Raquel Urtasun </a> <br>
           Raquel Urtasun is a Full Professor in the Department of Computer Science at the <a href="http://web.cs.toronto.edu/home.htm">University of Toronto</a> and a co-founder of the <a href="http://vectorinstitute.ai/">Vector Institute</a> for AI. From 2017 to 2021 she was the Chief Scientist and Head of R&D at <a href="https://www.uber.com/info/atg/">Uber ATG</a>. She is a world leading expert in AI for self-driving cars. Her research interests include machine learning, computer vision, robotics and remote sensing. Her lab was selected as an NVIDIA NVAIL lab. She is a recipient of an NSERC EWR Steacie Award, two NVIDIA Pioneers of AI Award, a Ministry of Education and Innovation Early Researcher Award, three Google Faculty Research Awards, an Amazon Faculty Research Award, a Connaught New Researcher Award, a Fallona Family Research Award  and two Best Paper Runner up Prize awarded at CVPR in 2013 and 2017. She was also named Chatelaine 2018 Woman of the year, and 2018 Toronto's top influencers by Adweek magazine. 
            </td>
          </tr>



        </tbody></table>
   <!-- 
    <table class="sponsors">
        <tr>
            <td class="sponsor">
                <a href="http://people.eecs.berkeley.edu/~malik/">
                    <img src="images/malik-color-small.gif" alt="Dr. Jitendra Malik", style="width: 60%">
                </a>
            </td>
            <td class="sponsor">
                <a href="https://www.researchgate.net/profile/Caroline_Pantofaru">
                    <img src="images/caroline_pantofaru.jpg" alt="Dr. Caroline Pantofaru", style="width: 60%">
                </a>
            </td>
            <td class="sponsor">
                <a href="http://www.cs.toronto.edu/~urtasun/">
                    <img src="images/raquel_uoft.jpg" alt="Dr. Raquel Urtasun", style="width: 60%">
                </a>
            </td>
        </tr>
        <tr>
            <td class="sponsor">
                <a href="http://people.eecs.berkeley.edu/~malik/">
                    Dr. Jitendra Malik
                </a>
            </td>
            <td class="sponsor">
                <a href="https://www.researchgate.net/profile/Caroline_Pantofaru">
                    Dr. Caroline Pantofaru
                </a>
            </td>
            <td class="sponsor">
                <a href="http://www.cs.toronto.edu/~urtasun/">
                   Dr. Raquel Urtasun
                </a>
            </td>
    
        </tr>
    </table>
   -->
    
    <h3> Schedule </h3>
  <p>(all times in EDT)</p> 
    <ul>
    <li>3:00 - 3:05pm: Opening remarks
    <ul></ul>
    </li>
    <li>3:05 - 3:35pm: Panel 1: Current limitations of computer vision datasets (<a href="fcvd_notes.pdf"> notes </a>)
        <ul style="margin-left: 40px;margin-top:0px">
        <li> Moderator: Prof. Bill Freeman </li>
        <li> Panelists: <a href="https://sites.google.com/site/asmabenabacha/">Dr. Asma Ben Abacha</a>, <a href="https://deeptigp.github.io">Dr. Deepti Ghadiyaram </a>, <a href="https://www.ischool.utexas.edu/~dannag/AboutMe.html">Dr. Danna Gurari</a> and <a href="https://wilddash.cc/about">Oliver Zendel</a>.  </li> 
        </ul>
    </li>        
   <li> 3:40 - 4:00pm: Invited speaker: <a href="http://people.eecs.berkeley.edu/~malik/">Dr. Jitendra Malik</a> (<a href="workshop.html">video</a>)
    <ul></ul>
   </li>
   <li> 4:00 - 4:30pm: Panel 2: Addressing scalability of large-scale diverse datasets(<a href="fcvd_notes.pdf"> notes </a>)
        <ul style="margin-left: 40px;margin-top:0px">
        <li> Panelists: <a href="http://people.eecs.berkeley.edu/~malik/">Dr. Jitendra Malik</a>, <a href="https://www.jeffreybyrne.com">Dr. Jeffrey Byrne</a>, <a href="http://olivalab.mit.edu/audeoliva.html">Dr. Aude Oliva</a> and <a href="https://sites.google.com/view/vittoferrari">Dr. Vittorio Ferrari</a></li>
        </ul>
   </li>
   <li> 4:35 - 4:55pm: Invited speaker: <a href="http://www.cs.toronto.edu/~urtasun/">Dr. Raquel Urtasun</a> (<a href="workshop.html">video</a>)
    <ul></ul>
   </li>
   <li> 4:55 - 5:15pm: Break
    <ul></ul></li>
   <li> 5:15 - 5:45pm: Open-mic discussion (<a href="fcvd_notes.pdf"> notes </a>)
        <ul style="margin-left: 40px;margin-top:0px">
        <li> Introductory message from <a href="https://dimadamen.github.io">Dr. Dima Damen</a> (full video <a href="workshop.html">here</a>) </li>    
        </ul></li>
   <li> 5:50 - 6:10pm: Invited speaker: <a href="https://cephaloponderer.com">Dr. Emily Denton</a> (<a href="assets/Denton_slides.pdf">slides</a>, <a href="workshop.html">video</a>)
   <ul></ul></li>
   <li> 6:10 - 6:40pm: Panel 3: Addressing privacy concerns and representational  harms(<a href="fcvd_notes.pdf"> notes </a>)
        <ul style="margin-left: 40px;margin-top:0px">
        <li> Introductory message from <a href="https://www.lizjosullivan.com">Dr. Liz O'Sullivan</a>
        <li> Panelists: <a href="http://solon.barocas.org">Dr. Solon Barocas</a>, <a href="https://cephaloponderer.com">Dr. Emily Denton</a></li>
        </ul>
   </li>
   <li> 6:40 - 7:00pm: Closing remarks, with summary of key takeaways</li>

    
    </ul>

    <h3>Organizers</h3>
    <ul>
    <li> <a href="https://www.cs.princeton.edu/~vr23/"> Vikram V. Ramaswamy </a> (Princeton)</li>
    <li> <a href="https://billf.mit.edu"> William T. Freeman</a>  (MIT) </li>
    <li> <a href="https://profiles.stanford.edu/fei-fei-li"> Fei-Fei Li </a> (Stanford) </li>
    <li> <a href=" http://www.vision.caltech.edu/Perona.html"> Pietro Perona </a> (CalTech)  </li>
    <li> <a href="https://groups.csail.mit.edu/vision/torralbalab"> Antonio Torralba </a> (MIT) </li>
    <li> <a href="https://www.cs.princeton.edu/~olgarus/index.html"> Olga Russakovsky </a> (Princeton)</li>
    </ul>

<!--    
    <table class="sponsors">
        <tr>
            <td class="sponsor">
                <a href="http://www.eyebleach.me/">
                    <img src="assets/kitten1.jpg" alt="First Sponsor Name">
                </a>
            </td>
            <td class="sponsor">
                <a href="http://www.eyebleach.me/">
                    <img src="assets/kitten2.jpg" alt="Second Sponsor Name" style="width: 80%">
                </a>
            </td>
            <td class="sponsor">
                <a href="http://www.eyebleach.me/">
                    <img src="assets/kitten3.jpg" alt="Third Sponsor Name">
                </a>
            </td>
        </tr>
    </table>
-->
    <table class="footer">
        <tr>
            <td class="footer"> <a href="https://github.com/mikepierce/conference-website-template">Website source</a></td> 
        </tr>
    </table>

    </body>
</html>

